{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando data sensível falsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_fake_csv_data import SensitiveDataGenerator\n",
    "\n",
    "sensitive_data_gen = SensitiveDataGenerator('pt_BR')\n",
    "sensitive_data_gen.write_csv_data_sensitive_only(name=\"dados_sensiveis_treino.csv\", title=['Dado A', 'Dado B', 'Dado C', 'tipo de dado'], size=170)\n",
    "sensitive_data_gen.write_csv_data_random(name=\"dados_sensiveis_teste.csv\", title=['Dado A', 'Dado B', 'Dado C', 'tipo de dado'], size=170)\n",
    "# sensitive_data_gen.write_csv_data_sensitive_only(size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports de bibliotecas importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.backend import clear_session\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# clear_session() -> limpa os pesos da antiga analise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo CSV e criando dados de teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Dado A            Dado B  \\\n",
      "0    Gustavo Henrique Pires     Android 2.3.4   \n",
      "1          João Pedro Souza     Android 3.2.6   \n",
      "2             Lívia Peixoto      675988235130   \n",
      "3           Francisco Pinto  6011570386264416   \n",
      "4               Julia Silva     4379450983931   \n",
      "..                      ...               ...   \n",
      "164          Juliana Aragão      676274897005   \n",
      "165           Clara Ribeiro  2714097944621712   \n",
      "166            Sophie Gomes   370948288984604   \n",
      "167     João Gabriel Campos     Android 5.0.2   \n",
      "168            Erick da Luz     Android 7.1.2   \n",
      "\n",
      "                                  Dado C  tipo de dado  \n",
      "0                                 Barman             0  \n",
      "1    Contramestre em transporte marítimo             0  \n",
      "2                           41 7143 1700             1  \n",
      "3                    +55 (021) 1623 9198             1  \n",
      "4                          0800 734 8229             1  \n",
      "..                                   ...           ...  \n",
      "164                  +55 (071) 4684 3878             1  \n",
      "165                  +55 (011) 3740 1646             1  \n",
      "166                         21 8758-4128             1  \n",
      "167                            Patinador             0  \n",
      "168                     Agente funerário             0  \n",
      "\n",
      "[169 rows x 4 columns]\n",
      "    Dado A Dado B Dado C  tipo de dado\n",
      "0        0      0      0             0\n",
      "1        1      1      1             0\n",
      "2        2      2      2             1\n",
      "3        3      3      3             1\n",
      "4        4      4      4             1\n",
      "..     ...    ...    ...           ...\n",
      "164    162    124    159             1\n",
      "165    163    125    160             1\n",
      "166    164    126    161             1\n",
      "167    165     32    162             0\n",
      "168    166    127    163             0\n",
      "\n",
      "[169 rows x 4 columns]\n",
      "[[  0   0   0]\n",
      " [  1   1   1]\n",
      " [  2   2   2]\n",
      " [  3   3   3]\n",
      " [  4   4   4]\n",
      " [  5   5   5]\n",
      " [  6   6   6]\n",
      " [  7   7   7]\n",
      " [  8   8   8]\n",
      " [  9   5   9]\n",
      " [ 10   9  10]\n",
      " [ 11  10  11]\n",
      " [ 12  11  12]\n",
      " [ 13  12  13]\n",
      " [ 14  13  14]\n",
      " [ 15  14  15]\n",
      " [ 16  15  16]\n",
      " [ 17   9  17]\n",
      " [ 18  16  18]\n",
      " [ 19  17  19]\n",
      " [ 20  18  20]\n",
      " [ 21  19  21]\n",
      " [ 22  20  22]\n",
      " [ 23  21  23]\n",
      " [ 24  22  24]\n",
      " [ 25  23  25]\n",
      " [ 26  24  26]\n",
      " [ 27  25  27]\n",
      " [ 28  26  28]\n",
      " [ 29  27  29]\n",
      " [ 30  28  30]\n",
      " [ 31  29  31]\n",
      " [ 32   0  32]\n",
      " [ 33  30  33]\n",
      " [ 34  31  34]\n",
      " [ 35  15  35]\n",
      " [ 36  32  36]\n",
      " [ 37  33  37]\n",
      " [ 38  34  38]\n",
      " [ 39  35  39]\n",
      " [ 40  36  40]\n",
      " [ 41  37  41]\n",
      " [ 42  38  42]\n",
      " [ 43  39  43]\n",
      " [ 44  40  44]\n",
      " [ 45  41  45]\n",
      " [ 46   0  46]\n",
      " [ 47  42  47]\n",
      " [ 48   5  48]\n",
      " [ 49  43  49]\n",
      " [ 50  44  50]\n",
      " [ 51  45  51]\n",
      " [ 52  46  52]\n",
      " [ 53  47  53]\n",
      " [ 54  15  54]\n",
      " [ 55  48  55]\n",
      " [ 56  49  56]\n",
      " [ 57  11  57]\n",
      " [ 58  50  58]\n",
      " [ 59  51  59]\n",
      " [ 60  21  60]\n",
      " [ 61  52  61]\n",
      " [ 62  53  62]\n",
      " [ 63  54  63]\n",
      " [ 64  55  64]\n",
      " [ 65  56  65]\n",
      " [ 66  57  66]\n",
      " [ 67  27  67]\n",
      " [ 68  58  68]\n",
      " [ 69  59  69]\n",
      " [ 70  60  70]\n",
      " [ 71  61  71]\n",
      " [ 72  62  72]\n",
      " [ 73  63  73]\n",
      " [ 74  64  74]\n",
      " [ 75  65  75]\n",
      " [ 76  66  76]\n",
      " [ 77   5  77]\n",
      " [ 78  67  78]\n",
      " [ 79   1  79]\n",
      " [ 80  68  80]\n",
      " [ 81  14  81]\n",
      " [ 82  69  82]\n",
      " [ 83  70  83]\n",
      " [ 84  71  84]\n",
      " [ 85  72  85]\n",
      " [ 86  73  86]\n",
      " [ 87  14  87]\n",
      " [ 88  74  88]\n",
      " [ 89  75  89]\n",
      " [ 90  76   0]\n",
      " [ 91  77  90]\n",
      " [ 92  78  91]\n",
      " [ 93  12  92]\n",
      " [ 94  79  93]\n",
      " [ 95  80  94]\n",
      " [ 96   1  95]\n",
      " [ 97  81  96]\n",
      " [ 98  82  97]\n",
      " [ 99  37  98]\n",
      " [100  83  99]\n",
      " [101  84 100]\n",
      " [102  21 101]\n",
      " [103  85 102]\n",
      " [104  86 103]\n",
      " [105  10 104]\n",
      " [106   8  10]\n",
      " [107  87 105]\n",
      " [108  88 106]\n",
      " [109  89 107]\n",
      " [110  47 108]\n",
      " [111  15 109]\n",
      " [112  17 110]\n",
      " [113  90 111]\n",
      " [114   8 112]\n",
      " [115  28 113]\n",
      " [116  91 114]\n",
      " [117  92 115]\n",
      " [118  93 116]\n",
      " [119  21 117]\n",
      " [120  94  12]\n",
      " [121  83 118]\n",
      " [122  95 119]\n",
      " [123  96 120]\n",
      " [124  97 121]\n",
      " [125  98 122]\n",
      " [126  80 123]\n",
      " [ 37  99 124]\n",
      " [127 100 125]\n",
      " [128 101 126]\n",
      " [129  25 127]\n",
      " [130  18 128]\n",
      " [131 102 129]\n",
      " [132  14 130]\n",
      " [133  28 131]\n",
      " [134 103 132]\n",
      " [135 104 133]\n",
      " [136  11 134]\n",
      " [137 105 135]\n",
      " [138 106 136]\n",
      " [139 107 137]\n",
      " [140  42 138]\n",
      " [141   0 139]\n",
      " [142   0 140]\n",
      " [143 108 141]\n",
      " [144 109 142]\n",
      " [145 110 143]\n",
      " [146 111 144]\n",
      " [147 112 145]\n",
      " [148 113 146]\n",
      " [149  37 147]\n",
      " [150 114  35]\n",
      " [151 115 148]\n",
      " [152  83 149]\n",
      " [153 116 150]\n",
      " [154   9 151]\n",
      " [155  12 152]\n",
      " [144 117 153]\n",
      " [156 118 154]\n",
      " [157 119 129]\n",
      " [158 120 155]\n",
      " [159 121 156]\n",
      " [160 122 157]\n",
      " [161 123 158]\n",
      " [162 124 159]\n",
      " [163 125 160]\n",
      " [164 126 161]\n",
      " [165  32 162]\n",
      " [166 127 163]] 507\n",
      "                     Dado A               Dado B               Dado C  \\\n",
      "0             Sarah da Mata     3584369065686187        0800-906-6806   \n",
      "1      Ana Beatriz Carvalho         676354164227  +55 (021) 6870-6573   \n",
      "2               Breno Silva      349682343363045      (061) 6283-3594   \n",
      "3           Lorena Ferreira  4284992195388489373      (051) 5655 9927   \n",
      "4    Luiz Henrique Monteiro      347154367842330     +55 51 3008 2810   \n",
      "..                      ...                  ...                  ...   \n",
      "164           Luna da Cunha     2271913905069177      (041) 2431 8948   \n",
      "165        Mariane da Costa     6586659263502587      (031) 6541-2299   \n",
      "166        Marcelo Teixeira      374855783263168         84 5731 9511   \n",
      "167              Bruno Dias         675912864617      (031) 4959 8507   \n",
      "168             Luana Pinto      342017523464338     +55 81 2231-5835   \n",
      "\n",
      "     tipo de dado  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "..            ...  \n",
      "164             1  \n",
      "165             1  \n",
      "166             1  \n",
      "167             1  \n",
      "168             1  \n",
      "\n",
      "[169 rows x 4 columns]\n",
      "    Dado A               Dado B Dado C  tipo de dado\n",
      "0        0     3584369065686187      0             1\n",
      "1        1         676354164227      1             1\n",
      "2        2      349682343363045      2             1\n",
      "3        3  4284992195388489373      3             1\n",
      "4        4      347154367842330      4             1\n",
      "..     ...                  ...    ...           ...\n",
      "164    162     2271913905069177    164             1\n",
      "165    163     6586659263502587    165             1\n",
      "166    164      374855783263168    166             1\n",
      "167    165         675912864617    167             1\n",
      "168    166      342017523464338    168             1\n",
      "\n",
      "[169 rows x 4 columns]\n",
      "[[                  0    3584369065686187                   0]\n",
      " [                  1        676354164227                   1]\n",
      " [                  2     349682343363045                   2]\n",
      " [                  3 4284992195388489373                   3]\n",
      " [                  4     347154367842330                   4]\n",
      " [                  5        569262754348                   5]\n",
      " [                  6    3502553552593100                   6]\n",
      " [                  7    3549127763220814                   7]\n",
      " [                  8     213164135022074                   8]\n",
      " [                  9    2700289497399905                   9]\n",
      " [                 10    6011228189437149                  10]\n",
      " [                 11    4189250077457345                  11]\n",
      " [                 12    3561215783720997                  12]\n",
      " [                 13     349240121216586                  13]\n",
      " [                 14 4466082194367295418                  14]\n",
      " [                 15    4670608192642628                  15]\n",
      " [                 16    6569945933357283                  16]\n",
      " [                 17    6565415314170915                  17]\n",
      " [                 18     213154931041071                  18]\n",
      " [                 19        630443613603                  19]\n",
      " [                 20 4552187447882109188                  20]\n",
      " [                 21    4185446259915290                  21]\n",
      " [                 22 4422726041373004679                  22]\n",
      " [                 23    3597104058743504                  23]\n",
      " [                 24    6533530347208596                  24]\n",
      " [                 25     180097450190390                  25]\n",
      " [                 26    3511402794175608                  26]\n",
      " [                 27       4070059342229                  27]\n",
      " [                 28 4087439247433096261                  28]\n",
      " [                 29    4751101636749516                  29]\n",
      " [                 30 4928985725139395486                  30]\n",
      " [                 31 4251647883928304321                  31]\n",
      " [                 32    6570418309267012                  32]\n",
      " [                 33    4482218773596629                  33]\n",
      " [                 34 4525457867298896822                  34]\n",
      " [                 35    3537317647970841                  35]\n",
      " [                 36    2251694887430983                  36]\n",
      " [                 37     347502759833228                  37]\n",
      " [                 38    4315908356608196                  38]\n",
      " [                 39    2418541739099443                  39]\n",
      " [                 40    3577881288597735                  40]\n",
      " [                 41       4913398584722                  41]\n",
      " [                 42    3538121750075607                  42]\n",
      " [                 43     347530227543913                  43]\n",
      " [                 44       4713304337052                  44]\n",
      " [                 45    2604054638215114                  45]\n",
      " [                 46     374434905382775                  46]\n",
      " [                 47 4940005494788185901                  47]\n",
      " [                 48 4105362993047025508                  48]\n",
      " [                 49    6011371058240960                  49]\n",
      " [                 50    5355672118264312                  50]\n",
      " [                 51     341553760159273                  51]\n",
      " [                 52        585515191419                  52]\n",
      " [                 53    4624258520606049                  53]\n",
      " [                 54      30165039116392                  54]\n",
      " [                 55 4783440864584988566                  55]\n",
      " [                 56      30441838834331                  56]\n",
      " [                 57     345007431740892                  57]\n",
      " [                 58    3580603210251966                  58]\n",
      " [                 59    4011552725941123                  59]\n",
      " [                 60     378441764004131                  60]\n",
      " [                 61    4389802768537922                  61]\n",
      " [                 62    4480605062634255                  62]\n",
      " [                 63    3581908864251900                  63]\n",
      " [                 64         60440693970                  64]\n",
      " [                 65        502049444230                  65]\n",
      " [                 66    3510456437853212                  66]\n",
      " [                 67     180011136501144                  67]\n",
      " [                 68        573139165829                  68]\n",
      " [                 69    3588543317328857                  69]\n",
      " [                 70    3563910647067001                  70]\n",
      " [                 71    4564385494789881                  71]\n",
      " [                 72    4561638142775923                  72]\n",
      " [                 73    3503661957170579                  73]\n",
      " [                 74     343868021300914                  74]\n",
      " [                 75       4877838626304                  75]\n",
      " [                 76       4829291155016                  76]\n",
      " [                 77     342575396935171                  77]\n",
      " [                 78      30123461424313                  78]\n",
      " [                 79    2674761832496598                  79]\n",
      " [                 80        630419838036                  80]\n",
      " [                 81    4927362851640645                  81]\n",
      " [                 82    3584161059200079                  82]\n",
      " [                 83    6588192443741220                  83]\n",
      " [                 84       4089371939801                  84]\n",
      " [                 85    3594607584093361                  85]\n",
      " [                 86    6581699486963369                  86]\n",
      " [                 87     373299602737857                  87]\n",
      " [                 88       4718593871265                  88]\n",
      " [                 89    6583706181691365                  89]\n",
      " [                 90      30131993837985                  90]\n",
      " [                 91    3548417058938530                  91]\n",
      " [                 92    3543575534031363                  92]\n",
      " [                 93    4990162162386223                  93]\n",
      " [                 94        630493692275                  94]\n",
      " [                 95    3528736899936658                  95]\n",
      " [                 96    3509347283008659                  96]\n",
      " [                 97    6011848168321871                  97]\n",
      " [                 98 4623671913163091363                  98]\n",
      " [                 99     180071562484439                  99]\n",
      " [                100    6011303087418358                 100]\n",
      " [                101     180062084913310                 101]\n",
      " [                102    3524416444062912                 102]\n",
      " [                103       4761332005555                 103]\n",
      " [                104       4916309442179                 104]\n",
      " [                105        630497680755                 105]\n",
      " [                106    4078484111419847                 106]\n",
      " [                107 4706813937345135410                 107]\n",
      " [                108    4538501587457995                 108]\n",
      " [                 29      38813258401506                 109]\n",
      " [                109    6568203131436082                 110]\n",
      " [                110       4922961495653                 111]\n",
      " [                111       4740063981192                 112]\n",
      " [                112    4354684739458326                 113]\n",
      " [                113     213158449700722                 114]\n",
      " [                114      36603594574484                 115]\n",
      " [                115     180003032742229                 116]\n",
      " [                116    5206372910538630                 117]\n",
      " [                117    4062693369730675                 118]\n",
      " [                118    3538267313083693                 119]\n",
      " [                119    3528664606771087                 120]\n",
      " [                120    6554712143049259                 121]\n",
      " [                121    4167399847926539                 122]\n",
      " [                122        584580474008                 123]\n",
      " [                123    2715236157018930                 124]\n",
      " [                124 4435518500489685766                 125]\n",
      " [                125 4901631126527065788                 126]\n",
      " [                126    4896616375482462                 127]\n",
      " [                127       4690828875579                 128]\n",
      " [                128       4279823244302                 129]\n",
      " [                129      30336051869339                 130]\n",
      " [                130    4813304532523839                 131]\n",
      " [                131    3519027041362162                 132]\n",
      " [                132      36083119123309                 133]\n",
      " [                133    2712584076615721                 134]\n",
      " [                134        502017891669                 135]\n",
      " [                135        630474160714                 136]\n",
      " [                136    4158025281644145                 137]\n",
      " [                137    3538264213663336                 138]\n",
      " [                138    3503067733605492                 139]\n",
      " [                139    6011179695145702                 140]\n",
      " [                140     213170419534197                 141]\n",
      " [                141    5144226305370295                 142]\n",
      " [                142    3577524852276845                 143]\n",
      " [                143    2256409556484731                 144]\n",
      " [                144     340731687160837                 145]\n",
      " [                145     372724558954280                 146]\n",
      " [                146     213110219389046                 147]\n",
      " [                147    3556268235135758                 148]\n",
      " [                148    3582331604316678                 149]\n",
      " [                149    3512842521533117                 150]\n",
      " [                150    4934281964424856                 151]\n",
      " [                151    6011886550795583                 152]\n",
      " [                152     375071143619086                 153]\n",
      " [                153     213108787481344                 154]\n",
      " [                154     180019913090850                 155]\n",
      " [                155 4191175439691936449                 156]\n",
      " [                156    4766958421610275                 157]\n",
      " [                157    3505964802659517                 158]\n",
      " [                158        574184761033                 159]\n",
      " [                159    6011986475281998                 160]\n",
      " [                160    3593588870981314                 161]\n",
      " [                132    2707327940954216                 162]\n",
      " [                161    3564170704857161                 163]\n",
      " [                162    2271913905069177                 164]\n",
      " [                163    6586659263502587                 165]\n",
      " [                164     374855783263168                 166]\n",
      " [                165        675912864617                 167]\n",
      " [                166     342017523464338                 168]] 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magoimortal\\AppData\\Local\\Temp\\ipykernel_11292\\3769023849.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  X_train.fillna(X_train.mean(), inplace=True)\n",
      "C:\\Users\\Magoimortal\\AppData\\Local\\Temp\\ipykernel_11292\\3769023849.py:39: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  X_test.fillna(X_test.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# SEÇÃO TREINAMENTO\n",
    "# Lendo dados de entrada.\n",
    "X_train = pd.read_csv(\"./dados_sensiveis_aleatorio.csv\")\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "\n",
    "columns = list(X_train)\n",
    "print(X_train)\n",
    "\n",
    "# Categorizando.\n",
    "for i in columns:\n",
    "    if X_train[i].dtypes == 'object':\n",
    "        X_train[i] = pd.Categorical(pd.factorize(X_train[i])[0])\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "# Fazendo o pré processamento.\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in columns:\n",
    "    if X_train[i].dtypes == 'object':\n",
    "        X_train[i] = le.fit_transform(X_train[i])\n",
    "\n",
    "y_train = X_train[\"tipo de dado\"]\n",
    "X_train.drop([\"tipo de dado\"], axis=1, inplace=True)\n",
    "\n",
    "# Criando variáveis de entradas\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "# Tamanhos das entradas.\n",
    "x_size:int = X_train.size\n",
    "y_size:int = y_train.size\n",
    "\n",
    "print(X_train, x_size)\n",
    "# FIM SESSÃO TREINAMENTO\n",
    "\n",
    "# SESSÃO DE TESTE.\n",
    "# Lendo dados de entrada.\n",
    "X_test = pd.read_csv(\"./dados_sensiveis_teste2.csv\")\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "\n",
    "columns = list(X_test)\n",
    "print(X_test)\n",
    "\n",
    "# Categorizando.\n",
    "for i in columns:\n",
    "    if X_test[i].dtypes == 'object':\n",
    "        X_test[i] = pd.Categorical(pd.factorize(X_test[i])[0])\n",
    "\n",
    "print(X_test)\n",
    "\n",
    "# Fazendo o pré processamento.\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in columns:\n",
    "    if X_test[i].dtypes == 'object':\n",
    "        X_test[i] = le.fit_transform(X_test[i])\n",
    "\n",
    "y_test = X_test[\"tipo de dado\"]\n",
    "X_test.drop([\"tipo de dado\"], axis=1, inplace=True)\n",
    "\n",
    "# Criando variáveis de entradas\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "print(X_test, x_size)\n",
    "# FIM SESSÃO DE TESTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                48        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# modelo baseado em uma pilha de layers, utilizando o layer mais comum Dense.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(12, input_dim = input_dim, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, input_dim = input_dim, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "# Configurando o modelo de treinamento.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary() # Mostra os paramestros disponíveis para treinar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e teste do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from plot_history_helper import plot_history\n",
    "from keras import callbacks\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"min\", patience = 5, restore_best_weights = True)\n",
    "\n",
    "# Treinando o modelo.\n",
    "#history = model.fit(\n",
    "#  X_train,\n",
    "#  y_train,\n",
    "#  epochs=10,\n",
    "#  verbose=2,\n",
    "#)\n",
    "\n",
    "# Mostrando resultados do treinamento com dataset de train.\n",
    "#pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "#plot.show()\n",
    "\n",
    "\n",
    "# Treinando o modelo.\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  epochs=12,\n",
    "  verbose=False,\n",
    "  validation_data=(X_test, y_test),\n",
    "  batch_size=20,\n",
    "  callbacks =[earlystopping]\n",
    ")\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Previsão no teste: 1.0\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Previsão no teste: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando 10 modelos e pegando 10 pedaços do dataset para comparar precisão entre os modelos Sequenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0]\n",
      " [  1   1   1]\n",
      " [  2   2   2]\n",
      " ...\n",
      " [972 578 868]\n",
      " [813 579 869]\n",
      " [973  18  24]] 507\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 12)                48        \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magoimortal\\AppData\\Local\\Temp\\ipykernel_11292\\3253694253.py:14: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  X.fillna(X.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.00%\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_93 (Dense)            (None, 12)                48        \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 94.00%\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 12)                48        \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 94.00%\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_99 (Dense)            (None, 12)                48        \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 90.00%\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_102 (Dense)           (None, 12)                48        \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 83.00%\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_105 (Dense)           (None, 12)                48        \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 89.00%\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 12)                48        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 91.00%\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_111 (Dense)           (None, 12)                48        \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 86.00%\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_114 (Dense)           (None, 12)                48        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 90.00%\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_117 (Dense)           (None, 12)                48        \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 92.93%\n",
      "[95.99999785423279, 93.99999976158142, 93.99999976158142, 89.99999761581421, 82.99999833106995, 88.99999856948853, 91.00000262260437, 86.00000143051147, 89.99999761581421, 92.92929172515869]\n",
      "90.59% (+/- 3.74%)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import random\n",
    "from plot_history_helper import plot_history\n",
    "from keras import callbacks\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Seed fix para poder reproduzir o \"teste\".\n",
    "seed = int(random.randint(0, 100))\n",
    "np.random.seed(seed)\n",
    "\n",
    "X = pd.read_csv(\"./dados_sensiveis.csv\")\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "#X = pd.read_csv(\"./dados_sensiveis_teste.csv\")\n",
    "#X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "columns = list(X)\n",
    "\n",
    "# Categorizando.\n",
    "for i in columns:\n",
    "    if X[i].dtypes == 'object':\n",
    "        X[i] = pd.Categorical(pd.factorize(X[i])[0])\n",
    "\n",
    "# Fazendo o pré processamento.\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in columns:\n",
    "    if X[i].dtypes == 'object':\n",
    "        X[i] = le.fit_transform(X[i])\n",
    "\n",
    "y = X[\"tipo de dado\"]\n",
    "X.drop([\"tipo de dado\"], axis=1, inplace=True)\n",
    "\n",
    "# Criando variáveis de entradas\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "print(X, x_size)\n",
    "\n",
    "# Pegando 10 cortes do dataset original de maneira aleatória.\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores:list = []\n",
    "# Criando 10 modelos com 10 datasets cortados pegos do dataset original e depois comparando os resultados.\n",
    "for train, test in kfold.split(X, y):\n",
    "  #print(test, train)\n",
    "  earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"min\", patience = 5, restore_best_weights = True)\n",
    "  # modelo baseado em uma pilha de layers, utilizando o layer mais comum Dense.\n",
    "  input_dim = X.shape[1]\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Dense(12, input_dim = input_dim, activation='relu'))\n",
    "  model.add(keras.layers.Dense(8, activation='relu'))\n",
    "  model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "  # Configurando o modelo de treinamento.\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  model.summary() # Mostra os paramestros disponíveis para treinar\n",
    "  #Treinando o modelo.\n",
    "  history = model.fit(\n",
    "    X[train],\n",
    "    y[train],\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "  )\n",
    "  scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "  #loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "  cvscores.append(scores[1] * 100)\n",
    "print(cvscores)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIANDO UM DATASET COM DADOS ALEATÓRIOS.\n",
    "sensitive_data_gen.write_csv_data_random(name=\"dados_sensiveis.csv\", title=['Dado A', 'Dado B', 'Dado C', 'tipo de dado'], size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Dado A               Dado B  \\\n",
      "0     Ana Júlia Nogueira     3576727104822164   \n",
      "1       Francisco Aragão  4049262843891670258   \n",
      "2        Pietra Silveira        Android 5.0.1   \n",
      "3         Alícia Martins     6011993136162724   \n",
      "4    João Pedro Oliveira     6011205866009706   \n",
      "..                   ...                  ...   \n",
      "994    Srta. Nina da Luz     4795049281258473   \n",
      "995   Srta. Amanda Pires        Android 4.4.1   \n",
      "996       Kaique da Mota     3511577041622138   \n",
      "997   Vitor Hugo Ribeiro     3556083070211527   \n",
      "998           Eloah Dias        Android 4.4.2   \n",
      "\n",
      "                                  Dado C  tipo de dado  \n",
      "0                           81 1874 8192             1  \n",
      "1                       +55 51 6947 5122             1  \n",
      "2                                Prático             0  \n",
      "3                        (041) 9985-3745             1  \n",
      "4                          0300-577-2226             1  \n",
      "..                                   ...           ...  \n",
      "994                         31 0747-8625             1  \n",
      "995  Tecnólogo em desenvolvimento social             0  \n",
      "996                  +55 (051) 8329 7123             1  \n",
      "997                      (051) 6516 9776             1  \n",
      "998    Profissional de efeitos especiais             0  \n",
      "\n",
      "[999 rows x 4 columns]\n",
      "    Dado A Dado B Dado C  tipo de dado\n",
      "0        0      0      0             1\n",
      "1        1      1      1             1\n",
      "2        2      2      2             0\n",
      "3        3      3      3             1\n",
      "4        4      4      4             1\n",
      "..     ...    ...    ...           ...\n",
      "994    970    577    866             1\n",
      "995    971    159    867             0\n",
      "996    972    578    868             1\n",
      "997    813    579    869             1\n",
      "998    973     18     24             0\n",
      "\n",
      "[999 rows x 4 columns]\n",
      "[[  0   0   0]\n",
      " [  1   1   1]\n",
      " [  2   2   2]\n",
      " ...\n",
      " [972 578 868]\n",
      " [813 579 869]\n",
      " [973  18  24]] 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magoimortal\\AppData\\Local\\Temp\\ipykernel_11292\\107258690.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  X.fillna(X.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# USANDO EM UM CASO \"REAL\".\n",
    "# Lendo dados de entrada.\n",
    "X = pd.read_csv(\"./dados_sensiveis.csv\")\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "#X = pd.read_csv(\"./dados_sensiveis_teste.csv\")\n",
    "#X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "columns = list(X)\n",
    "print(X)\n",
    "\n",
    "# Categorizando.\n",
    "for i in columns:\n",
    "    if X[i].dtypes == 'object':\n",
    "        X[i] = pd.Categorical(pd.factorize(X[i])[0])\n",
    "\n",
    "print(X)\n",
    "\n",
    "# Fazendo o pré processamento.\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in columns:\n",
    "    if X[i].dtypes == 'object':\n",
    "        X[i] = le.fit_transform(X[i])\n",
    "\n",
    "y = X[\"tipo de dado\"]\n",
    "X.drop([\"tipo de dado\"], axis=1, inplace=True)\n",
    "\n",
    "# Criando variáveis de entradas\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "print(X, x_size)\n",
    "# FIM USANDO EM UM CASO \"REAL\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.2332 - accuracy: 0.9059 - 91ms/epoch - 3ms/step\n",
      "Previsão no teste: 0.9059059023857117\n"
     ]
    }
   ],
   "source": [
    "# Vendo versão final do resultado.\n",
    "clear_session()\n",
    "\n",
    "loss, accuracy = model.evaluate(X, y, verbose=2)\n",
    "print(f\"Previsão no teste: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
